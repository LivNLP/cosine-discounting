{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ec2662-269f-4302-88c3-7a0aad193471",
   "metadata": {},
   "source": [
    "# Load WiC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffc7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafb3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"path_to_WiC\", sep='\\t',header=None)\n",
    "data.columns = ['keyword', 'POS', 'indices', 'sentence1', 'sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005fb73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>POS</th>\n",
       "      <th>indices</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carry</td>\n",
       "      <td>V</td>\n",
       "      <td>2-1</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>V</td>\n",
       "      <td>2-6</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>break</td>\n",
       "      <td>V</td>\n",
       "      <td>0-2</td>\n",
       "      <td>Break an alibi .</td>\n",
       "      <td>The wholesaler broke the container loads into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>N</td>\n",
       "      <td>8-4</td>\n",
       "      <td>He wore a jock strap with a metal cup .</td>\n",
       "      <td>Bees filled the waxen cups with honey .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy</td>\n",
       "      <td>N</td>\n",
       "      <td>1-2</td>\n",
       "      <td>The Academy of Music .</td>\n",
       "      <td>The French Academy .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword POS indices                                       sentence1  \\\n",
       "0    carry   V     2-1              You must carry your camping gear .   \n",
       "1       go   V     2-6  Messages must go through diplomatic channels .   \n",
       "2    break   V     0-2                                Break an alibi .   \n",
       "3      cup   N     8-4         He wore a jock strap with a metal cup .   \n",
       "4  academy   N     1-2                          The Academy of Music .   \n",
       "\n",
       "                                           sentence2  \n",
       "0                    Sound carries well over water .  \n",
       "1   Do you think the sofa will go through the door ?  \n",
       "2  The wholesaler broke the container loads into ...  \n",
       "3            Bees filled the waxen cups with honey .  \n",
       "4                               The French Academy .  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ddb497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5428, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3434135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  human_label\n",
       "0           F\n",
       "1           F\n",
       "2           F\n",
       "3           T\n",
       "4           F"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_labels = pd.read_csv(\"path_to_gold_labels\", sep = '\\t', header=None)\n",
    "gold_labels.columns=['human_label']\n",
    "gold_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44393d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>POS</th>\n",
       "      <th>indices</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>human_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carry</td>\n",
       "      <td>V</td>\n",
       "      <td>2-1</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>V</td>\n",
       "      <td>2-6</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>break</td>\n",
       "      <td>V</td>\n",
       "      <td>0-2</td>\n",
       "      <td>Break an alibi .</td>\n",
       "      <td>The wholesaler broke the container loads into ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>N</td>\n",
       "      <td>8-4</td>\n",
       "      <td>He wore a jock strap with a metal cup .</td>\n",
       "      <td>Bees filled the waxen cups with honey .</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy</td>\n",
       "      <td>N</td>\n",
       "      <td>1-2</td>\n",
       "      <td>The Academy of Music .</td>\n",
       "      <td>The French Academy .</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword POS indices                                       sentence1  \\\n",
       "0    carry   V     2-1              You must carry your camping gear .   \n",
       "1       go   V     2-6  Messages must go through diplomatic channels .   \n",
       "2    break   V     0-2                                Break an alibi .   \n",
       "3      cup   N     8-4         He wore a jock strap with a metal cup .   \n",
       "4  academy   N     1-2                          The Academy of Music .   \n",
       "\n",
       "                                           sentence2 human_label  \n",
       "0                    Sound carries well over water .           F  \n",
       "1   Do you think the sofa will go through the door ?           F  \n",
       "2  The wholesaler broke the container loads into ...           F  \n",
       "3            Bees filled the waxen cups with honey .           T  \n",
       "4                               The French Academy .           F  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.set_index(data.index).join(gold_labels.set_index(gold_labels.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8054ec-99b6-4da7-9778-44383602c8dc",
   "metadata": {},
   "source": [
    "# Load pre-trained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5e212d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to('cuda')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899fb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import tagset_mapping, map_tag\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "793dd590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create word embedding\n",
    "def emb(text, target_index):\n",
    "    tokens = text.lower().split(' ')\n",
    "    tokenized_words = []\n",
    "    emb_index = []\n",
    "    tokenized_words.append('[CLS]')\n",
    "    for word_sim in tokens:\n",
    "        len_now = 0\n",
    "        for tokenized in tokenizer.tokenize(word_sim):\n",
    "            len_now+=1\n",
    "            tokenized_words.append(tokenized)\n",
    "        emb_index.append([len(tokenized_words) -1 - i for i in range(len_now)])\n",
    "    tokenized_words.append('[SEP]')\n",
    "    #print(tokenized_words) #########################################################\n",
    "    #print(emb_index) #########################################################\n",
    "    \n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_words)\n",
    "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "    segments_ids = [1] * len(tokenized_words)\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    \n",
    "    #tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "    #segments_tensors = torch.tensor([segments_ids]).to('cuda')\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "    return sum([encoded_layers[11][0][temp_index].to('cpu') for temp_index in emb_index[target_index]])/len(emb_index[target_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29914bf-0ee5-430b-ba16-17a8845356c8",
   "metadata": {},
   "source": [
    "# Default BERT prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d92277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the default prediction\n",
    "default = []\n",
    "for index in range(len(data)):\n",
    "    text1 = data.iloc[index]['sentence1']\n",
    "    target_index1 = int(data.iloc[index]['indices'].split('-')[0])\n",
    "    text2 = data.iloc[index]['sentence2']\n",
    "    target_index2 = int(data.iloc[index]['indices'].split('-')[1])\n",
    "    emb1 = emb(text1, target_index1)\n",
    "    emb2 = emb(text2, target_index2)\n",
    "    cos = torch.cosine_similarity(emb1.reshape(1,-1), emb2.reshape(1,-1))[0].item()\n",
    "    if cos >= 0.5:\n",
    "        default.append('T')\n",
    "    else:\n",
    "        default.append('F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc6dcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>POS</th>\n",
       "      <th>indices</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>human_label</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carry</td>\n",
       "      <td>V</td>\n",
       "      <td>2-1</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>V</td>\n",
       "      <td>2-6</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>break</td>\n",
       "      <td>V</td>\n",
       "      <td>0-2</td>\n",
       "      <td>Break an alibi .</td>\n",
       "      <td>The wholesaler broke the container loads into ...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>N</td>\n",
       "      <td>8-4</td>\n",
       "      <td>He wore a jock strap with a metal cup .</td>\n",
       "      <td>Bees filled the waxen cups with honey .</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy</td>\n",
       "      <td>N</td>\n",
       "      <td>1-2</td>\n",
       "      <td>The Academy of Music .</td>\n",
       "      <td>The French Academy .</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword POS indices                                       sentence1  \\\n",
       "0    carry   V     2-1              You must carry your camping gear .   \n",
       "1       go   V     2-6  Messages must go through diplomatic channels .   \n",
       "2    break   V     0-2                                Break an alibi .   \n",
       "3      cup   N     8-4         He wore a jock strap with a metal cup .   \n",
       "4  academy   N     1-2                          The Academy of Music .   \n",
       "\n",
       "                                           sentence2 human_label default  \n",
       "0                    Sound carries well over water .           F       F  \n",
       "1   Do you think the sofa will go through the door ?           F       T  \n",
       "2  The wholesaler broke the container loads into ...           F       F  \n",
       "3            Bees filled the waxen cups with honey .           T       T  \n",
       "4                               The French Academy .           F       T  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['default'] = pd.Series(default)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19795d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862564480471629\n"
     ]
    }
   ],
   "source": [
    "# default acc\n",
    "score=0\n",
    "for index in range(len(data)):\n",
    "    if data.iloc[index]['human_label'] == data.iloc[index]['default']:\n",
    "        score+=1\n",
    "print(score/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7bb60d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003229"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add word frequency to data\n",
    "import joblib\n",
    "record = joblib.load('path_to_record_dictionary')\n",
    "# key = (word, word type i.e. VERB, stop or non-stop word), value = [frequency]\n",
    "len(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb47633a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negotiate', 'VERB', 'NON_STOP'), [3094]),\n",
       " (('negotiate', 'NOUN', 'NON_STOP'), [188]),\n",
       " (('negotiate', 'ADJ', 'NON_STOP'), [102]),\n",
       " (('negotiate', 'ADV', 'NON_STOP'), [16]),\n",
       " (('negotiate', 'ADP', 'NON_STOP'), [7]),\n",
       " (('negotiate', 'DET', 'NON_STOP'), [1])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for (k,v) in record.items() if k[0]=='negotiate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17fbe079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found commercialization\n",
      "not found ulteriority\n",
      "not found hyponym\n",
      "not found ulteriority\n",
      "not found ulteriority\n",
      "not found negociate\n",
      "not found hyponym\n",
      "not found shtik\n",
      "not found commercialization\n",
      "not found etiolation\n",
      "not found hyponym\n",
      "not found summerize\n",
      "not found misplay\n",
      "not found commercialization\n"
     ]
    }
   ],
   "source": [
    "# record the word frequency and log-2 frequency\n",
    "freq=[]\n",
    "log2freq=[]\n",
    "for index in range(len(data)):\n",
    "    word = data.iloc[index]['keyword']\n",
    "    if data.iloc[index]['POS'] == 'V':\n",
    "        pos = 'VERB'\n",
    "    else:\n",
    "        pos = 'NOUN'\n",
    "    if word in gensim.parsing.preprocessing.STOPWORDS:\n",
    "        stop = 'STOP'\n",
    "    else:\n",
    "        stop = 'NON_STOP'\n",
    "    if (word, pos, stop) in record.keys(): \n",
    "        freq.append(record[(word, pos, stop)][0])\n",
    "        log2freq.append(np.log2(record[(word, pos, stop)][0]))\n",
    "    else:\n",
    "        if (word, stop) in [(k[0], k[2]) for (k,v) in record.items()]:\n",
    "            temp = [v for (k,v) in record.items() if k[0]==word and k[2]==stop]\n",
    "            if len(temp) ==1:\n",
    "                freq.append(temp[0][0])\n",
    "                log2freq.append(np.log2(temp[0][0]))\n",
    "            else:\n",
    "                print('not found', word)\n",
    "                freq.append('not found')\n",
    "                log2freq.append('not found')\n",
    "        else:\n",
    "            print('not found', word)\n",
    "            freq.append('not found')\n",
    "            log2freq.append('not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff575bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>POS</th>\n",
       "      <th>indices</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>human_label</th>\n",
       "      <th>default</th>\n",
       "      <th>freq</th>\n",
       "      <th>log2freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carry</td>\n",
       "      <td>V</td>\n",
       "      <td>2-1</td>\n",
       "      <td>You must carry your camping gear .</td>\n",
       "      <td>Sound carries well over water .</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>51781</td>\n",
       "      <td>15.660135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>V</td>\n",
       "      <td>2-6</td>\n",
       "      <td>Messages must go through diplomatic channels .</td>\n",
       "      <td>Do you think the sofa will go through the door ?</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>1425686</td>\n",
       "      <td>20.443225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>break</td>\n",
       "      <td>V</td>\n",
       "      <td>0-2</td>\n",
       "      <td>Break an alibi .</td>\n",
       "      <td>The wholesaler broke the container loads into ...</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>92773</td>\n",
       "      <td>16.501417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>N</td>\n",
       "      <td>8-4</td>\n",
       "      <td>He wore a jock strap with a metal cup .</td>\n",
       "      <td>Bees filled the waxen cups with honey .</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>59218</td>\n",
       "      <td>15.853748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academy</td>\n",
       "      <td>N</td>\n",
       "      <td>1-2</td>\n",
       "      <td>The Academy of Music .</td>\n",
       "      <td>The French Academy .</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>8268</td>\n",
       "      <td>13.013323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword POS indices                                       sentence1  \\\n",
       "0    carry   V     2-1              You must carry your camping gear .   \n",
       "1       go   V     2-6  Messages must go through diplomatic channels .   \n",
       "2    break   V     0-2                                Break an alibi .   \n",
       "3      cup   N     8-4         He wore a jock strap with a metal cup .   \n",
       "4  academy   N     1-2                          The Academy of Music .   \n",
       "\n",
       "                                           sentence2 human_label default  \\\n",
       "0                    Sound carries well over water .           F       F   \n",
       "1   Do you think the sofa will go through the door ?           F       T   \n",
       "2  The wholesaler broke the container loads into ...           F       F   \n",
       "3            Bees filled the waxen cups with honey .           T       T   \n",
       "4                               The French Academy .           F       T   \n",
       "\n",
       "      freq   log2freq  \n",
       "0    51781  15.660135  \n",
       "1  1425686  20.443225  \n",
       "2    92773  16.501417  \n",
       "3    59218  15.853748  \n",
       "4     8268  13.013323  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['freq'] = pd.Series(freq)\n",
    "data['log2freq'] = pd.Series(log2freq)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93dfc52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5414"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(data[data['freq'] == 'not found'].index)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdacab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5414, step=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.reset_index()\n",
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e65fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859992611747322\n"
     ]
    }
   ],
   "source": [
    "# default acc\n",
    "score=0\n",
    "for index in range(len(data)):\n",
    "    if data.iloc[index]['human_label'] == data.iloc[index]['default']:\n",
    "        score+=1\n",
    "print(score/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec70cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('WIC_default_freq_V1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4689ea-3b0e-46f1-9c29-166d55bd7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the word embedding\n",
    "emb_1 = []\n",
    "emb_2 = []\n",
    "for index in range(len(data)):\n",
    "    text1 = data.iloc[index]['sentence1']\n",
    "    target_index1 = int(data.iloc[index]['indices'].split('-')[0])\n",
    "    text2 = data.iloc[index]['sentence2']\n",
    "    target_index2 = int(data.iloc[index]['indices'].split('-')[1])\n",
    "    emb1 = emb(text1, target_index1)\n",
    "    emb2 = emb(text2, target_index2)\n",
    "    emb_1.append(emb1)\n",
    "    emb_2.append(emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6dcb15-0799-46f6-afa1-1a278e01730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emb1'] = pd.Series(emb_1)\n",
    "data['emb2'] = pd.Series(emb_2)\n",
    "data.to_csv('WIC_default_V3_emb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0691a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default BERT prediction\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "freq = [np.log2(i[1][0]) for i in sorted(record.items(), key=lambda x:-x[1][0]) if i[0][2]=='NON_STOP' and i[0][1] in ['NOUN','VERB']]\n",
    "no_bin = 10\n",
    "move = max(freq)/no_bin\n",
    "x=[j for j in range(1,11)]\n",
    "y_sim=[]\n",
    "y_dissim=[]\n",
    "for index in range(no_bin):\n",
    "    left = index*move\n",
    "    if index == no_bin-1:\n",
    "        right = max(freq)+1\n",
    "    else:\n",
    "        right = (index+1)*move\n",
    "    F = data[(data['human_label'] == 'F') & (data['log2freq']>= left) & (data['log2freq']< right)]\n",
    "    T = data[(data['human_label'] == 'T') & (data['log2freq']>= left) & (data['log2freq']< right)]\n",
    "    F_F = F[F['default']=='F']\n",
    "    T_T = T[T['default']=='T']\n",
    "    y_dissim.append(len(F_F)/len(F))\n",
    "    y_sim.append(len(T_T)/len(T))\n",
    "    #print(len(T), len(T_T))\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "N = 10\n",
    "\n",
    "ind = np.arange(N) \n",
    "width = 0.35       \n",
    "plt.bar(ind, y_sim, width, label='sim')\n",
    "plt.bar(ind + width, y_dissim, width,\n",
    "    label='dissim')\n",
    "\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('bin')\n",
    "plt.title('acc of default BERT')\n",
    "\n",
    "plt.xticks(ind + width / 2, x)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea1d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
