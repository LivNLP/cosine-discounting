1. ano1 prepare BookCorpus: 
- download and save BookCorpus dataset

2. ano2 word embedding and BERT properties collection: 
- collect word embedding, word frequency, and l2-norm from the entire BookCorpus
 
3. ano3 word frequency VS l2_norm: 
- plots between word frequency and l2-norm

4. ano4 WIC preprocess:
- Process WiC by adding word frequency, default BERT cosine similarity, and BERT word embedding

5. ano5 theta of the classifier:
- Bayesian optimization to find the theta of the classifier

6. ano6 WIC 5 cross validation dataset prep:
- Prepare 5 cross-validations dataset from WiC

7. ano7 l2_norm discounting:
- Cosine similarity prediction of the l2-norm discounting method compared to default BERT
